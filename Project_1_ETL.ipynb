{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFat298q3XHV8anfIAozOa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/newGitHub1234/Project_1_ETL/blob/main/Project_1_ETL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GV2D6HYPKtTj",
        "outputId": "4e5124f4-253e-4a7a-8965-fa72cc029002"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing JSON file: source1.json\n",
            "Warning: Error processing file 'source1.json': Extra data: line 2 column 1 (char 47)\n",
            "Processing XML file: source2.xml\n",
            "Processing CSV file: transformed_data.csv\n",
            "Unsupported file type: log_file.txt\n",
            "Processing CSV file: source2.csv\n",
            "Processing JSON file: source2.json\n",
            "Warning: Error processing file 'source2.json': Extra data: line 2 column 1 (char 47)\n",
            "Processing XML file: source1.xml\n",
            "Processing XML file: source3.xml\n",
            "Processing CSV file: source3.csv\n",
            "Processing CSV file: source1.csv\n",
            "Processing JSON file: source3.json\n",
            "Warning: Error processing file 'source3.json': Extra data: line 2 column 1 (char 47)\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "import datetime\n",
        "import csv\n",
        "import json\n",
        "import os\n",
        "import logging\n",
        "import pytz\n",
        "\n",
        "# Getting the IST timezone\n",
        "\n",
        "ist_timezone = pytz.timezone('Asia/Kolkata')\n",
        "\n",
        "# Converting current time to IST\n",
        "\n",
        "current_time_ist = datetime.datetime.now(ist_timezone)\n",
        "\n",
        "# Format the time with IST\n",
        "\n",
        "formatted_time_ist = current_time_ist.strftime('%Y-%m-%d %H:%M:%S.%f %Z%z')\n",
        "\n",
        "# Main folder path\n",
        "\n",
        "folder_path = '/content/Project_ETL'\n",
        "\n",
        "# Configuring logging\n",
        "\n",
        "logging.basicConfig(filename='/content/log_file.txt', level=logging.INFO,\n",
        "                    format=f'{formatted_time_ist} - %(levelname)s - %(message)s',\n",
        "                    datefmt='%Y-%m-%d %H:%M:%S', force=True)\n",
        "\n",
        "# Function to extract data from CSV file\n",
        "\n",
        "def extract_csv(file_path):\n",
        "    logging.info(f\"Extraction - Starting to process CSV file: {file_path}\")\n",
        "    data = []\n",
        "    with open(file_path, mode='r', newline='', encoding='utf-8') as file:\n",
        "        reader = csv.DictReader(file)\n",
        "        for row in reader:\n",
        "            data.append(row)\n",
        "    logging.info(f\"Extraction - Finished processing CSV file: {file_path}\")\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Function to extract data from JSON file\n",
        "\n",
        "def extract_json(file_path):\n",
        "    logging.info(f\"Extraction - Starting to process JSON file: {file_path}\")\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        data = json.load(file)\n",
        "    logging.info(f\"Extraction - Finished processing JSON file: {file_path}\")\n",
        "    #print(\"json data\", data)\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Function to extract data from XML file\n",
        "\n",
        "def extract_xml(file_path):\n",
        "    logging.info(f\"Extraction - Starting to process XML file: {file_path}\")\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    data = []\n",
        "    for elem in root:\n",
        "        data.append({child.tag: child.text for child in elem})\n",
        "    logging.info(f\"Extraction - Finished processing XML file: {file_path}\")\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Function to Process the files with extensions and Transform extracted Data\n",
        "\n",
        "def process_files(folder_path, filename):\n",
        "\n",
        "    file_path = os.path.join(folder_path, filename)\n",
        "    file_extension = filename.split('.')[-1].lower()\n",
        "\n",
        "    try:\n",
        "        if file_extension == 'csv':\n",
        "            print(f\"Processing CSV file: {filename}\")\n",
        "            data = extract_csv(file_path)\n",
        "        elif file_extension == 'json':\n",
        "            print(f\"Processing JSON file: {filename}\")\n",
        "            data = extract_json(file_path)\n",
        "        elif file_extension == 'xml':\n",
        "            print(f\"Processing XML file: {filename}\")\n",
        "            data = extract_xml(file_path)\n",
        "        else:\n",
        "            print(f\"Unsupported file type: {filename}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        return data\n",
        "\n",
        "    except (pd.errors.EmptyDataError, json.JSONDecodeError, ET.ParseError) as e:\n",
        "        print(f\"Warning: Error processing file '{filename}': {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "\n",
        "# Function to process the files and combine data\n",
        "\n",
        "def process_all_files_in_folder(folder_path):\n",
        "    logging.info(f\"Processing - Starting to process all files in folder: {folder_path}\")\n",
        "\n",
        "    all_data_frames = []\n",
        "\n",
        "    file_paths = glob.glob(os.path.join(folder_path, '*'))\n",
        "\n",
        "    for file_path in file_paths:\n",
        "        filename = os.path.basename(file_path)\n",
        "        df = process_files(folder_path, filename)\n",
        "        if not df.empty:\n",
        "            all_data_frames.append(df)\n",
        "\n",
        "    if all_data_frames:\n",
        "        combined_data = pd.concat(all_data_frames, ignore_index=True)\n",
        "    else:\n",
        "        print(\"Warning: No valid data files found in the folder.\")\n",
        "        combined_data = pd.DataFrame()\n",
        "\n",
        "    logging.info(f\"Processing - Finished processing all files in folder: {folder_path}\")\n",
        "    return combined_data\n",
        "\n",
        "# Processing all the files in the folder\n",
        "\n",
        "combined_df = process_all_files_in_folder(folder_path)\n",
        "\n",
        "# Converting combined_df to pandas dataframe\n",
        "\n",
        "df = pd.DataFrame(combined_df)\n",
        "\n",
        "# Conversion function\n",
        "\n",
        "def convert_units(df):\n",
        "\n",
        "    # Convert height from inches to meters\n",
        "\n",
        "    df['Height_meters'] = pd.to_numeric(df['height']) * 0.0254\n",
        "\n",
        "    # Convert weight from pounds to kilograms\n",
        "\n",
        "    df['Weight_kg'] = pd.to_numeric(df['weight']) * 0.453592\n",
        "\n",
        "    return df\n",
        "\n",
        "# Converting the units\n",
        "\n",
        "df_converted = convert_units(df)\n",
        "\n",
        "# Saving the final output, combined data Dataframe to a CSV file\n",
        "\n",
        "output_file_path = '/content/transformed_data.csv'\n",
        "df_converted.to_csv(output_file_path, index=False)\n",
        "logging.info(f\"Loading - Transformed data saved to: {output_file_path}\")\n"
      ]
    }
  ]
}